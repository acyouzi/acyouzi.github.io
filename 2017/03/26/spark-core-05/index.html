<!DOCTYPE html>
<html lang>
  <head><meta name="generator" content="Hexo 3.9.0">
    
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width,user-scalable=no,initial-scale=1,minimum-scale=1,maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">



  <meta name="description" content="Spark源码-Core-05-persist&&checkpoint&&blockManager">




  <meta name="keywords" content="spark,">





  <link rel="alternate" href="/default" title="爱吃柚子">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=1.1">



<link rel="canonical" href="http://acyouzi.com/2017/03/26/spark-core-05/">


<meta name="description" content="cache 方法实际上调用的是 MEMORY_ONLY level 的 Persist 设置过 persist 的 rdd 在调用时会在实际计算时调用 getOrCompute,如果存在直接从缓存中拿结果，否则重新计算并交给 blockManager 缓存 checkpoint 使用之前需要先调用 sc.setCheckpointDir() 设置缓存目录.目录最好设置在分布式文件系统上 chec">
<meta name="keywords" content="spark">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark源码-Core-05-persist&amp;&amp;checkpoint&amp;&amp;blockManager">
<meta property="og:url" content="http://acyouzi.com/2017/03/26/spark-core-05/index.html">
<meta property="og:site_name" content="爱吃柚子">
<meta property="og:description" content="cache 方法实际上调用的是 MEMORY_ONLY level 的 Persist 设置过 persist 的 rdd 在调用时会在实际计算时调用 getOrCompute,如果存在直接从缓存中拿结果，否则重新计算并交给 blockManager 缓存 checkpoint 使用之前需要先调用 sc.setCheckpointDir() 设置缓存目录.目录最好设置在分布式文件系统上 chec">
<meta property="og:locale" content="zh">
<meta property="og:updated_time" content="2019-08-07T14:02:39.513Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Spark源码-Core-05-persist&amp;&amp;checkpoint&amp;&amp;blockManager">
<meta name="twitter:description" content="cache 方法实际上调用的是 MEMORY_ONLY level 的 Persist 设置过 persist 的 rdd 在调用时会在实际计算时调用 getOrCompute,如果存在直接从缓存中拿结果，否则重新计算并交给 blockManager 缓存 checkpoint 使用之前需要先调用 sc.setCheckpointDir() 设置缓存目录.目录最好设置在分布式文件系统上 chec">


<link rel="stylesheet" type="text/css" href="/css/style.css?v=1.1">
<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">





<script type="text/javascript">
  var themeConfig = {
    fancybox: {
      enable: false
    },
  };
</script>




  
  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d310e8dddd6fde3a70c9b10c17107ae3";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>


  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-89126170-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-89126170-1');
  </script>



    <title> Spark源码-Core-05-persist&&checkpoint&&blockManager - 爱吃柚子 </title>
  </head>

  <body>
    <div id="page">
      <header id="masthead"><div class="site-header-inner">
    <h1 class="site-title">
        <a href="/." class="logo">爱吃柚子</a>
    </h1>

    <nav id="nav-top">
        
            <ul id="menu-top" class="nav-top-items">
                
                    <li class="menu-item">
                        <a href="/archives">
                            
                            
                                Archives
                            
                        </a>
                    </li>
                
                    <li class="menu-item">
                        <a href="/about">
                            
                            
                                About
                            
                        </a>
                    </li>
                
            </ul>
        
  </nav>
</div>

      </header>
      <div id="content">
        
    <div id="primary">
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          Spark源码-Core-05-persist&&checkpoint&&blockManager
        
      </h1>

      <time class="post-time">
          Mar 26 2017
      </time>
    </header>
    
            <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
            <!-- 长条 -->
            <ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4100561021751428" data-ad-slot="8938846166" data-ad-format="auto" data-full-width-responsive="true"></ins>
            <script>
                (adsbygoogle = window.adsbygoogle || []).push({});
            </script>
            <div class="post-content">
            <ol>
<li>cache 方法实际上调用的是 MEMORY_ONLY level 的 Persist</li>
<li>设置过 persist 的 rdd 在调用时会在实际计算时调用 getOrCompute,如果存在直接从缓存中拿结果，否则重新计算并交给 blockManager 缓存</li>
<li>checkpoint 使用之前需要先调用 sc.setCheckpointDir() 设置缓存目录.目录最好设置在分布式文件系统上</li>
<li>checkpoint 执行的时机是在任务 rdd 执行结束之后在 sc.runJob 中调用最后一个 rdd 的 doCheckpoint 方法</li>
<li>doCheckpoint 方法会重新提交 job 运行以存储 rdd,因为 rdd 的计算逻辑时如果存在 persist 数据直接从缓存中取，所以最好在想要 checkpoint 的地方先调用 persist, 否则会重新计算这个 rdd 的数据</li>
<li>checkpoint 会改变 rdd 的 lineage</li>
<li>Broadcast Variable 可以使得需要共享的变量在每个节点保存一份而不是在每个 task 上，减少了网络 io 和内存消耗。</li>
</ol>
<h2 id="cache"><a href="#cache" class="headerlink" title="cache()"></a>cache()</h2><pre><code>Persist this RDD with the default storage level (`MEMORY_ONLY`)    </code></pre><h2 id="persist"><a href="#persist" class="headerlink" title="persist()"></a>persist()</h2><pre><code>def persist(newLevel: StorageLevel): this.type = {
  if (isLocallyCheckpointed) {
    // 已经缓存过，transformStorageLevel 会给缓存级别上加一个磁盘
    persist(LocalRDDCheckpointData.transformStorageLevel(newLevel), allowOverride = true)
  } else {
    persist(newLevel, allowOverride = false)
  }
}</code></pre><p>在 iterator 会检查缓存级别，如果缓存了，先去缓存中拿。</p>
<pre><code>final def iterator(split: Partition, context: TaskContext): Iterator[T] = {
  if (storageLevel != StorageLevel.NONE) {
    getOrCompute(split, context)
  } else {
    computeOrReadCheckpoint(split, context)
  }
}</code></pre><p>最终会调用 blockManager 的 getOrElseUpdate 方法</p>
<pre><code>  def getOrElseUpdate[T](
      blockId: BlockId,
      level: StorageLevel,
      classTag: ClassTag[T],
      makeIterator: () =&gt; Iterator[T]): Either[BlockResult, Iterator[T]] = {
    // 从本地或者远程 blockmanager 读
    get[T](blockId)(classTag) match {
      case Some(block) =&gt;
        return Left(block)
      case _ =&gt;
        // Need to compute the block.
    }
    // 重新计算，重新缓存
    // makeIterator 是重新计算的函数
    // 形式 
    // () =&gt; {
    //   readCachedBlock = false
    //   // 重新计算
    //   computeOrReadCheckpoint(partition, context)
    // }
    // doPutIterator 略长，就不贴了主要做了如下事情
    //  1. 根据设置的内存磁盘缓存级别，还有是否序列化做处理
    //  2. 报告 blockManagerMaster 状态变化 
    doPutIterator(blockId, makeIterator, level, classTag, keepReadLock = true) match {
      case None =&gt;
        // doPut() 啥都没做，可能多线程?别的线程做完了?
        val blockResult = getLocalValues(blockId).getOrElse {
          releaseLock(blockId)
          throw new SparkException(s&quot;get() failed for block $blockId even though we held a lock&quot;)
        }
        // 释放锁，返回结果
        releaseLock(blockId)
        Left(blockResult)
      case Some(iter) =&gt;
        // 数据太大内存放不下， dropped 到磁盘，通过迭代器返回
       Right(iter)
    }
  }

下面是 get 方法

     def get[T: ClassTag](blockId: BlockId): Option[BlockResult] = {
        val local = getLocalValues(blockId)
        if (local.isDefined) {
          logInfo(s&quot;Found block $blockId locally&quot;)
          return local
        }
        // 远程的要连接远程节点的 blockManager 获取
        // 要通过 blockManagerMaster 获取 block 在哪些节点上
        // 然后再从远程节点的 blockManager 上获取
        val remote = getRemoteValues[T](blockId)
        if (remote.isDefined) {
          logInfo(s&quot;Found block $blockId remotely&quot;)
          return remote
        }
        None
      }</code></pre><h2 id="checkpoint"><a href="#checkpoint" class="headerlink" title="checkpoint()"></a>checkpoint()</h2><pre><code>def checkpoint(): Unit = RDDCheckpointData.synchronized {
  if (context.checkpointDir.isEmpty) {
    throw new SparkException(&quot;Checkpoint directory has not been set in the SparkContext&quot;)
  } else if (checkpointData.isEmpty) {
    // 初始化
    checkpointData = Some(new ReliableRDDCheckpointData(this))
  }
}</code></pre><p>然后在 sparkContext 的 runJob 方法，注意最后一行，在 job 执行完成之后调用 rdd 的 doCheckpoint 方法。</p>
<pre><code>def runJob[T, U: ClassTag](
rdd: RDD[T],
func: (TaskContext, Iterator[T]) =&gt; U,
partitions: Seq[Int],
resultHandler: (Int, U) =&gt; Unit): Unit = {
  if (stopped.get()) {
    throw new IllegalStateException(&quot;SparkContext has been shutdown&quot;)
  }
  val callSite = getCallSite
  val cleanedFunc = clean(func)
  logInfo(&quot;Starting job: &quot; + callSite.shortForm)
  if (conf.getBoolean(&quot;spark.logLineage&quot;, false)) {
    logInfo(&quot;RDD&apos;s recursive dependencies:\n&quot; + rdd.toDebugString)
  }
  dagScheduler.runJob(rdd, cleanedFunc, partitions, callSite, resultHandler, localProperties.get)
  progressBar.foreach(_.finishAll())
  rdd.doCheckpoint()
}</code></pre><p>再看 doCheckpoint 方法</p>
<pre><code>private[spark] def doCheckpoint(): Unit = {
  RDDOperationScope.withScope(sc, &quot;checkpoint&quot;, allowNesting = false, ignoreParent = true) {
    if (!doCheckpointCalled) {
      doCheckpointCalled = true
      // 递归的往前找，直到有一个定义了 checkpointData
      if (checkpointData.isDefined) {
        if (checkpointAllMarkedAncestors) {
          // 继续往下走
          // 从第一个 checkpoint 的地方开始调用 checkpointData.get.checkpoint()
          dependencies.foreach(_.rdd.doCheckpoint())
        }
        checkpointData.get.checkpoint()
      } else {
        dependencies.foreach(_.rdd.doCheckpoint())
      }
    }
  }
}</code></pre><p>下面是 RDDCheckpointData#checkpoint 方法</p>
<pre><code>final def checkpoint(): Unit = {
  // Guard against multiple threads checkpointing the same RDD by
  // atomically flipping the state of this RDDCheckpointData
  RDDCheckpointData.synchronized {
    if (cpState == Initialized) {
      // 标记状态为 CheckpointingInProgress
      cpState = CheckpointingInProgress
    } else {
      return
    }
  }

  // 新建一个 RDD
  val newRDD = doCheckpoint()

  // 更改状态为 Checkpointed，并且改变依赖关系(lineage)
  RDDCheckpointData.synchronized {
    cpRDD = Some(newRDD)
    cpState = Checkpointed
    // 清理 rdd 原有的依赖
    rdd.markCheckpointed()
  }
}</code></pre><p>这个是 doCheckpoint 方法创建 ReliableCheckpointRDD 的代码，在这里面完成了 checkpoint 文件存储操作。</p>
<pre><code>def writeRDDToCheckpointDirectory[T: ClassTag](
    originalRDD: RDD[T],
    checkpointDir: String,
    blockSize: Int = -1): ReliableCheckpointRDD[T] = {
  val sc = originalRDD.sparkContext

  // Create the output path for the checkpoint
  val checkpointDirPath = new Path(checkpointDir)
  val fs = checkpointDirPath.getFileSystem(sc.hadoopConfiguration)
  if (!fs.mkdirs(checkpointDirPath)) {
    throw new SparkException(s&quot;Failed to create checkpoint path $checkpointDirPath&quot;)
  }

  // Save to file, and reload it as an RDD
  val broadcastedConf = sc.broadcast(
    new SerializableConfiguration(sc.hadoopConfiguration))

  // 划重点 -- writePartitionToCheckpointFile 就是把数据写的持久化目录中的方法
  // 比如写到 hdfs 的某个目录
  // 这个 runjob 是重新提交 job 
  // 这也是为什么想要 checkpoint 的节点最好先 persist 一下的原因。
  // 如果不 persist 那么需要 checkpoint 的数据需要从头跑一遍。
  // writePartitionToCheckpointFile 的方法就不贴了, 没什么意思
  sc.runJob(originalRDD,
    writePartitionToCheckpointFile[T](checkpointDirPath.toString, broadcastedConf) _)
  if (originalRDD.partitioner.nonEmpty) {
    writePartitionerToCheckpointDir(sc, originalRDD.partitioner.get, checkpointDirPath)
  }
  val newRDD = new ReliableCheckpointRDD[T](
    sc, checkpointDirPath.toString, originalRDD.partitioner)
  if (newRDD.partitions.length != originalRDD.partitions.length) {
    throw new SparkException(
      s&quot;Checkpoint RDD $newRDD(${newRDD.partitions.length}) has different &quot; +
        s&quot;number of partitions from original RDD $originalRDD(${originalRDD.partitions.length})&quot;)
  }
  newRDD
}</code></pre><p>下面看一看 checkpoint rdd 是怎么起作用的：</p>
<pre><code>private[spark] def computeOrReadCheckpoint(split: Partition, context: TaskContext): Iterator[T] =
{
  // isCheckpointedAndMaterialized 在checkpoint 过的节点返回为真
  if (isCheckpointedAndMaterialized) {
    // 比较关键的是 firstParent 怎么的到的，具体看下面的方法
    firstParent[T].iterator(split, context)
  } else {
    compute(split, context)
  }
}</code></pre><p>在 firstParent 方法中会去拿依赖的 head, 依赖获取的方法如下： </p>
<pre><code>final def dependencies: Seq[Dependency[_]] = {
  // 如果 checkpoint 有值直接返回
  checkpointRDD.map(r =&gt; List(new OneToOneDependency(r))).getOrElse {
    if (dependencies_ == null) {
      dependencies_ = getDependencies
    }
    dependencies_
  }
}</code></pre><p>到这里 checkpoint 的原理机制就介绍完了</p>
<h2 id="闭包处理"><a href="#闭包处理" class="headerlink" title="闭包处理"></a>闭包处理</h2><p>如果看过 spark 算子实现的代码你肯定会疑惑在每个 spark 算子中都会出现的下面这句话到底做了什么 </p>
<pre><code>val cleanF = sc.clean(f)</code></pre><p>这里辗转调用最终调用到一个非常长的方法 ClosureCleaner#clean, clean 方法内部使用了 asm 代码库直接分析字节码去确定闭包引用,然后在每个 task 上都会 copy 一份闭包引用，也就是说每个 task 有一份变量实例。因为 asm 库不太熟悉，等以后再补上代码分析..</p>
<h2 id="Broadcast-Variable-amp-amp-Accumulator"><a href="#Broadcast-Variable-amp-amp-Accumulator" class="headerlink" title="Broadcast Variable &amp;&amp; Accumulator"></a>Broadcast Variable &amp;&amp; Accumulator</h2><p>就不看代码了，看吐了，简单介绍下特点</p>
<p>一个算子的函数中使用到了某个外部的变量，那么这个变量的值会被拷贝到每个task中，此时每个task只能操作自己的那份变量副本，也就是闭包清理步骤做的事情。如果想要在多个 task 间共享一份数据这种方法是不恰当的，应该使用 Broadcast Variable（广播变量）或者 Accumulator（累加变量），Broadcast Variable会将使用到的变量仅在每个节点拷贝一份，而不是在每个 task 上(底层使用 blockManager 实现)，减少网络传输以及内存消耗。</p>
<p>Accumulator 提供了累加的功能，但是task只能对Accumulator进行累加操作，不能读取它的值，只有Driver程序可以读取Accumulator的值。</p>
<h2 id="blockManager"><a href="#blockManager" class="headerlink" title="blockManager"></a>blockManager</h2><p>这是 spark 中非常底层的部分，shuffle、persist、Broadcast 等都要用到它，blockMangerMaster 在 Driver 上启动，负责保存各个节点上 block 的状态每个 executor 上有 blockManager 负责管理本节点上的数据缓存，以及状态到 BlockManagerMaster 的报备。</p>
<p>… 有空再补上吧, 找实习烦死了</p>

            </div>
          

    
      <footer class="post-footer">
		
		<div class="post-tags">
		  
			<a href="/tags/spark/">spark</a>
		  
		</div>
		

        
        
  <nav class="post-nav">
    
      <a class="prev" href="/2017/04/03/spark-streaming-00/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">Spark源码-streaming-00-ReceiverTracker 数据接收</span>
        <span class="prev-text nav-mobile">Prev</span>
      </a>
    
    
      <a class="next" href="/2017/03/23/spark-core-04/">
        <span class="next-text nav-default">Spark源码-Core-04-shuffle过程</span>
        <span class="prev-text nav-mobile">Next</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>

        
  <div class="comments" id="comments">
    
  </div>


      </footer>
    
  </article>

    </div>

      </div>

      <footer id="colophon"><span class="copyright-year">
    
        &copy;
    
        2016 -
    
    2019
    <span class="footer-author">acyouzi.</span>
</span>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>
    


    




  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  

    <script type="text/javascript" src="/js/src/theme.js?v=1.1"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=1.1"></script>

  </body>
</html>
