<!DOCTYPE html>
<html lang>
  <head><meta name="generator" content="Hexo 3.9.0">
    
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width,user-scalable=no,initial-scale=1,minimum-scale=1,maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">



  <meta name="description" content="使用 docker 搭建 hadoop ha 集群">




  <meta name="keywords" content="java,">





  <link rel="alternate" href="/default" title="爱吃柚子">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=1.1">



<link rel="canonical" href="http://acyouzi.com/2016/11/01/hadoop-docker-cluster/">


<meta name="description" content="准备材料首先为什么要使用Docker来搭建集群呢，因为我是在本机测试搭建hadoop集群，在本机性能不是超强的情况下，开七八个虚拟机的确还是比较困难的事情。所在这里使用Docker来搭建，相比于开多台虚拟机，使用Docker对机器的要求显然要低的多 首先我们需要准备的材料有如下几项：  jdk-8u102-linux-x64.tar.gz zookeeper-3.4.9.tar.gz hadoop">
<meta name="keywords" content="java">
<meta property="og:type" content="article">
<meta property="og:title" content="使用 docker 搭建 hadoop ha 集群">
<meta property="og:url" content="http://acyouzi.com/2016/11/01/hadoop-docker-cluster/index.html">
<meta property="og:site_name" content="爱吃柚子">
<meta property="og:description" content="准备材料首先为什么要使用Docker来搭建集群呢，因为我是在本机测试搭建hadoop集群，在本机性能不是超强的情况下，开七八个虚拟机的确还是比较困难的事情。所在这里使用Docker来搭建，相比于开多台虚拟机，使用Docker对机器的要求显然要低的多 首先我们需要准备的材料有如下几项：  jdk-8u102-linux-x64.tar.gz zookeeper-3.4.9.tar.gz hadoop">
<meta property="og:locale" content="zh">
<meta property="og:updated_time" content="2019-08-07T14:02:11.276Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="使用 docker 搭建 hadoop ha 集群">
<meta name="twitter:description" content="准备材料首先为什么要使用Docker来搭建集群呢，因为我是在本机测试搭建hadoop集群，在本机性能不是超强的情况下，开七八个虚拟机的确还是比较困难的事情。所在这里使用Docker来搭建，相比于开多台虚拟机，使用Docker对机器的要求显然要低的多 首先我们需要准备的材料有如下几项：  jdk-8u102-linux-x64.tar.gz zookeeper-3.4.9.tar.gz hadoop">


<link rel="stylesheet" type="text/css" href="/css/style.css?v=1.1">
<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">





<script type="text/javascript">
  var themeConfig = {
    fancybox: {
      enable: false
    },
  };
</script>




  
  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d310e8dddd6fde3a70c9b10c17107ae3";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>


  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-89126170-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-89126170-1');
  </script>


  <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- 方框 -->
  <ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4100561021751428" data-ad-slot="1154304039" data-ad-format="auto" data-full-width-responsive="true"></ins>
  <script>
      (adsbygoogle = window.adsbygoogle || []).push({});
  </script>



    <title> 使用 docker 搭建 hadoop ha 集群 - 爱吃柚子 </title>
  </head>

  <body>
    <div id="page">
      <header id="masthead"><div class="site-header-inner">
    <h1 class="site-title">
        <a href="/." class="logo">爱吃柚子</a>
    </h1>

    <nav id="nav-top">
        
            <ul id="menu-top" class="nav-top-items">
                
                    <li class="menu-item">
                        <a href="/archives">
                            
                            
                                Archives
                            
                        </a>
                    </li>
                
                    <li class="menu-item">
                        <a href="/about">
                            
                            
                                About
                            
                        </a>
                    </li>
                
            </ul>
        
  </nav>
</div>

      </header>
      <div id="content">
        
    <div id="primary">
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          使用 docker 搭建 hadoop ha 集群
        
      </h1>

      <time class="post-time">
          Nov 01 2016
      </time>
    </header>
    
            <div class="post-content">
            <h3 id="准备材料"><a href="#准备材料" class="headerlink" title="准备材料"></a>准备材料</h3><p>首先为什么要使用Docker来搭建集群呢，因为我是在本机测试搭建hadoop集群，在本机性能不是超强的情况下，开七八个虚拟机的确还是比较困难的事情。所在这里使用Docker来搭建，相比于开多台虚拟机，使用Docker对机器的要求显然要低的多</p>
<p>首先我们需要准备的材料有如下几项：</p>
<ul>
<li>jdk-8u102-linux-x64.tar.gz</li>
<li>zookeeper-3.4.9.tar.gz</li>
<li>hadoop-2.7.3.tar.gz</li>
</ul>
<p>以上是我在配置集群时的最新版本，当然也可以自行选择其他版本。</p>
<p>然后新建一个目录 ~/docker-file 把上面的安装包都拷贝进去</p>
<pre><code>cd ~
mkdir docker-file</code></pre><p>其次需要准备ssh的秘钥，用于配置秘钥登录</p>
<pre><code>ssh-keygen -t rsa -b 2048
cp ~/.ssh/* ~/docker-file/</code></pre><p>准备 config 文件，config 文件用于配置ssh不用在第一次登录时输入yes确认，config 文件内容如下</p>
<pre><code>StrictHostKeyChecking no
# 每次都是新的 know host 文件
UserKnownHostsFile /dev/null</code></pre><h3 id="安装Docker"><a href="#安装Docker" class="headerlink" title="安装Docker"></a>安装Docker</h3><ol>
<li><p>首先看看内核版本，貌似不要低于3.10就好，一般ubuntu 14.04是没啥问题的</p>
<pre><code>uname -a</code></pre></li>
<li><p>添加apt源</p>
<pre><code>apt-get install apt-transport-https ca-certificates
apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80    --recv-keys    58118E89F3A912897C070ADBF76221572C52609D
apt-get update
apt-get install -y linux-image-extra-$(uname -r)
apt-get install -y docker-engine</code></pre></li>
<li><p>安装Docker</p>
<pre><code>apt-get    install    -y    docker-engine
# 测试一下看是否安装成功
docker -v</code></pre></li>
<li><p>安装pipework</p>
<pre><code>git clone https://github.com/jpetazzo/pipework
cp ~/pipework/pipework /usr/local/bin/</code></pre></li>
<li><p>安装 bridge-utils，配置网桥</p>
<pre><code>brctl addbr br0
brctl stp br1 off
ifconfig br0 192.168.0.1/24</code></pre></li>
</ol>
<h3 id="编写Dockerfile"><a href="#编写Dockerfile" class="headerlink" title="编写Dockerfile"></a>编写Dockerfile</h3><ol>
<li><p>pull docker image</p>
<pre><code># 可以去 hub.docker.com 上选择合适的镜像，但是可能网速比较慢
# 这里我们从网易蜂巢的仓库中选一个ubuntu的镜像,镜像中默认集成了openssh-server
# 下载镜像
docker pull hub.c.163.com/public/ubuntu:16.04
# 查看镜像 
docker images</code></pre></li>
<li><p>编写Dockerfile</p>
<pre><code># 指定基于哪个镜像创建docker
FROM hub.c.163.com/ubuntu:16.04
MAINTAINER acyouzi &lt;acyouzi@acyouzi.com&gt;

# 切换工作目录
WORKDIR /opt/

# jdk 安装
COPY jdk-8u102-linux-x64.tar.gz /opt/
RUN tar -xf jdk-8u102-linux-x64.tar.gz
RUN echo &quot;export JAVA_HOME=&apos;/opt/jdk1.8.0_102&apos;&quot; &gt;&gt; /etc/profile
RUN echo &quot;export PATH=\$PATH:\$JAVA_HOME/bin&quot; &gt;&gt; /etc/profile 

# zookeeper-3.4.9
COPY zookeeper-3.4.9.tar.gz /opt/
RUN tar -xf zookeeper-3.4.9.tar.gz
RUN echo &quot;export ZOOKEEPER_HOME=&apos;/opt/zookeeper-3.4.9&apos;&quot; &gt;&gt; /etc/profile
RUN echo &quot;export PATH=\$PATH:\$ZOOKEEPER_HOME/bin&quot; &gt;&gt; /etc/profile

# hadoop-2.7.3
COPY hadoop-2.7.3.tar.gz /opt/
RUN tar -xf hadoop-2.7.3.tar.gz
RUN echo &quot;export HADOOP_HOME=&apos;/opt/hadoop-2.7.3&apos;&quot; &gt;&gt; /etc/profile
RUN echo &quot;export PATH=\$PATH:\$HADOOP_HOME/bin:\$HADOOP_HOME/sbin&quot; &gt;&gt; /etc/profile

# add ssh key
RUN mkdir /root/.ssh
COPY id_rsa /root/.ssh/
COPY id_rsa.pub /root/.ssh/
COPY config /root/.ssh/
WORKDIR /root/.ssh
RUN cat id_rsa.pub &gt;&gt; authorized_keys

# sshd -D
ENTRYPOINT /usr/sbin/sshd -D

WORKDIR /</code></pre></li>
</ol>
<h3 id="build-dockerfile"><a href="#build-dockerfile" class="headerlink" title="build dockerfile"></a>build dockerfile</h3><pre><code>docker build ~/docker-file -t bigdata:1.0.0

# 查看镜像，会发现多了一个bigdata:1.0.0
docker images

# 测试创建容器
docker run -itd --name=test bigdata:1.0.0

# 查看运行的容器
docker ps

# 查看docker ip 地址
docker inspect -f &apos;{{ .NetworkSettings.IPAddress }}&apos; test

# ssh 远程登录
ssh root@&lt;ip&gt;

# 登录之后可以尝试运行几个命令看看软件是否安装成功
java -version
hadoop version</code></pre><h3 id="集群规划"><a href="#集群规划" class="headerlink" title="集群规划"></a>集群规划</h3><p>首先需要确定有哪几种类型的节点，以及节点数量</p>
<ul>
<li>zookeeper 集群，由3个节点组成，同时会成为journalnode</li>
<li>resourcemanager 两个节点</li>
<li>namenode 两个节点</li>
<li>datanode 三个节点</li>
</ul>
<p>这样我们节点就由:</p>
<blockquote>
<p>zookeeper1,zookeeper2,zookeeper3<br>resourcemanager1,resourcemanager2<br>namenode1,namenode2<br>datanode1,datanode2,datanode3<br>这十个节点组成。</p>
</blockquote>
<h3 id="准备配置文件"><a href="#准备配置文件" class="headerlink" title="准备配置文件"></a>准备配置文件</h3><p>根据我们的节点规划来编写对应的配置文件</p>
<ol start="0">
<li><p>新建文件夹 cluster-build，下面准备的所有文件都放到该目录下</p>
<pre><code>mkdir ~/cluster-build </code></pre></li>
<li><p>从 hadoop安装目录下的 /etc/hadoop/ 目录下拷贝 hadoop_env.sh 到 ~/cluster-build/</p>
<pre><code># 修改 hadoop_env.sh 文件的 JAVA_HOME 修改为dockerfile里面java安装的目录
export JAVA_HOME=&apos;/opt/jdk1.8.0_102&apos;</code></pre></li>
<li><p>core-site.xml</p>
<pre><code>&lt;configuration&gt;
&lt;!-- set nameservice --&gt;
&lt;property&gt;
    &lt;name&gt;fs.defaultFS&lt;/name&gt;
    &lt;value&gt;hdfs://acyouzi/&lt;/value&gt;
&lt;/property&gt;
&lt;!-- hadoop tmp dir --&gt;
&lt;property&gt;
    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
    &lt;value&gt;/root/hadoop&lt;/value&gt;
&lt;/property&gt;
&lt;!-- set zookeeper addr --&gt;
&lt;property&gt;
    &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;
    &lt;value&gt;zookeeper1:2181,zookeeper2:2181,zookeeper3:2181&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;</code></pre></li>
<li><p>mapred-site.xml</p>
<pre><code>&lt;configuration&gt;
&lt;property&gt;
    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
    &lt;value&gt;yarn&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt; </code></pre></li>
<li><p>hdfs-site.xml</p>
<pre><code>&lt;configuration&gt;
&lt;!--nameservice 配置为acyouzi,与core-site.xml中统一 --&gt;
&lt;property&gt;
    &lt;name&gt;dfs.nameservices&lt;/name&gt;
    &lt;value&gt;acyouzi&lt;/value&gt;
&lt;/property&gt;
&lt;!-- nameservice下边的namenode地址，两个 --&gt;
&lt;property&gt;
    &lt;name&gt;dfs.ha.namenodes.acyouzi&lt;/name&gt;
    &lt;value&gt;namenode1,namenode2&lt;/value&gt;
&lt;/property&gt;
&lt;!-- RPC地址 --&gt;
&lt;property&gt;
    &lt;name&gt;dfs.namenode.rpc-address.acyouzi.namenode1&lt;/name&gt;
    &lt;value&gt;namenode1:9000&lt;/value&gt;
&lt;/property&gt;
&lt;!-- http地址 --&gt;
&lt;property&gt;
    &lt;name&gt;dfs.namenode.http-address.acyouzi.namenode1&lt;/name&gt;
    &lt;value&gt;namenode1:50070&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;dfs.namenode.rpc-address.acyouzi.namenode2&lt;/name&gt;
    &lt;value&gt;namenode2:9000&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;dfs.namenode.http-address.acyouzi.namenode2&lt;/name&gt;
    &lt;value&gt;namenode2:50070&lt;/value&gt;
&lt;/property&gt;
&lt;!-- 放在JournalNode的哪里--&gt;
&lt;property&gt;
    &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;
    &lt;value&gt;qjournal://zookeeper1:8485;zookeeper2:8485;zookeeper3:8485/acyouzi&lt;/value&gt;
&lt;/property&gt;
&lt;!-- JournalNode本地数据放置位置 --&gt;
&lt;property&gt;
    &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;
    &lt;value&gt;/root/journaldata&lt;/value&gt;
&lt;/property&gt;
&lt;!-- namenode自动切换 --&gt;
&lt;property&gt;
    &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
&lt;!-- 失败自动切换方式，官方文档中有详细介绍 --&gt;
&lt;property&gt;
    &lt;name&gt;dfs.client.failover.proxy.provider.acyouzi&lt;/name&gt;
    &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;
&lt;/property&gt;
&lt;!-- fencing 隔离配置 --&gt;
&lt;property&gt;
    &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;
    &lt;value&gt;
    sshfence
    shell(/bin/true)
    &lt;/value&gt;
&lt;/property&gt;
&lt;!-- fence隔离 ssh 配置 --&gt;
&lt;property&gt;
    &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;
    &lt;value&gt;/root/.ssh/id_rsa&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;dfs.ha.fencing.ssh.connect-timeout&lt;/name&gt;
    &lt;value&gt;30000&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;</code></pre></li>
<li><p>yarn-site.xml</p>
<pre><code>&lt;configuration&gt;
&lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
&lt;!-- 指定RM的cluster id --&gt;
&lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt;
    &lt;value&gt;yrc&lt;/value&gt;
&lt;/property&gt;
&lt;!-- resourcemanager 名字和地址配置 --&gt;
&lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt;
    &lt;value&gt;rm1,rm2&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt;
    &lt;value&gt;resourcemanager1&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt;
    &lt;value&gt;resourcemanager2&lt;/value&gt;
&lt;/property&gt;
&lt;!-- zk cluster --&gt;
&lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt;
    &lt;value&gt;zookeeper1:2181,zookeeper2:2181,zookeeper3:2181&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;</code></pre></li>
<li><p>zoo.cfg</p>
<pre><code>tickTime=2000
initLimit=10
syncLimit=5

# 数据存放目录 myid会放在这下面
dataDir=/root/zookeeper
clientPort=2181

# zk 集群地址
server.1=zookeeper1:2888:3888
server.2=zookeeper2:2888:3888
server.3=zookeeper3:2888:3888</code></pre></li>
</ol>
<ol start="7">
<li><p>编写 zk-id.sh 脚本</p>
<pre><code>#!/bin/bash
echo $1 &gt; /root/zookeeper/myid</code></pre><p> 修改权限为可以执行</p>
<pre><code>chmod 775 zk-id.sh</code></pre></li>
</ol>
<h3 id="编写hadoop集群脚本"><a href="#编写hadoop集群脚本" class="headerlink" title="编写hadoop集群脚本"></a>编写hadoop集群脚本</h3><ol>
<li><p>在 ~/cluster-build 目录下创建 hadoop-cluster.sh 文件</p>
<pre><code>#!/bin/bash

# 定义用于拷贝配置文件，分配ip地址的函数
function cp_config(){
    docker exec ${1}${2} cp /root/cluster-build/hadoop-env.sh /opt/hadoop-2.7.3/etc/hadoop/
    docker exec ${1}${2} cp /root/cluster-build/core-site.xml /opt/hadoop-2.7.3/etc/hadoop/
    docker exec ${1}${2} cp /root/cluster-build/hdfs-site.xml /opt/hadoop-2.7.3/etc/hadoop/
    docker exec ${1}${2} cp /root/cluster-build/yarn-site.xml /opt/hadoop-2.7.3/etc/hadoop/
    docker exec ${1}${2} cp /root/cluster-build/mapred-site.xml /opt/hadoop-2.7.3/etc/hadoop/

    docker exec ${1}${2} cp /root/cluster-build/hosts /etc
    pipework br0 ${1}${2} 192.168.0.$((${3}+${2}-1))/24
}

# 删除上次创建的hosts配置
test -e hosts&amp;&amp; rm hosts

# 定义集群数量和集群起始ip分配地址
declare -i zk_num=3
declare -i zk_ipbase=2
declare -i rm_num=2
declare -i rm_ipbase=20
declare -i nn_num=2
declare -i nn_ipbase=40
declare -i dn_num=3
declare -i dn_ipbase=60

# hosts configration
echo 127.0.0.1 localhost.localdomain localhost &gt;&gt; hosts
for ((i=1; i&lt;=${zk_num}; i=i+1 ))
do
    echo 192.168.0.$((${zk_ipbase}+${i}-1))    zookeeper${i} &gt;&gt; hosts
done
for ((i=1; i&lt;=${rm_num}; i=i+1 ))
do
    echo 192.168.0.$((${rm_ipbase}+${i}-1))    resourcemanager${i} &gt;&gt; hosts
done
for ((i=1; i&lt;=${nn_num}; i=i+1 ))
do
    echo 192.168.0.$((${nn_ipbase}+${i}-1))    namenode${i} &gt;&gt; hosts
done
for ((i=1; i&lt;=${dn_num}; i=i+1 ))
do
    echo 192.168.0.$((${dn_ipbase}+${i}-1))    datanode${i} &gt;&gt; hosts
done

# zookeeper
for ((i=1; i&lt;=${zk_num}; i=i+1 ))
do
    docker run -itd -h zookeeper${i} --name=zookeeper${i} -v /root/cluster-build:/root/cluster-build bigdata:1.0.2
    docker exec zookeeper${i} mkdir /root/zookeeper
    docker exec zookeeper${i} /root/cluster-build/myid.sh ${i}
    docker exec zookeeper${i} cp /root/cluster-build/zoo.cfg /opt/zookeeper-3.4.9/conf
    cp_config &apos;zookeeper&apos; ${i} ${zk_ipbase}
done

# resourcemanager
# slaves 文件在启动集群时会用到
test -e slaves &amp;&amp; rm slaves
for ((i=1; i&lt;=${rm_num}; i=i+1 ))
do
    echo resourcemanager${i} &gt;&gt; slaves
done
for ((i=1; i&lt;=${rm_num}; i=i+1 ))
do
    docker run -itd -h resourcemanager${i} --name=resourcemanager${i} -v /root/cluster-build:/root/cluster-build bigdata:1.0.2
    docker exec resourcemanager${i} cp /root/cluster-build/slaves /opt/hadoop-2.7.3/etc/hadoop/
    cp_config &apos;resourcemanager&apos; ${i} ${rm_ipbase}
done

# namenode
for ((i=1; i&lt;=${nn_num}; i=i+1 ))
do
    docker run -itd -h namenode${i} --name=namenode${i} -v /root/cluster-build:/root/cluster-build bigdata:1.0.2
    cp_config &apos;namenode&apos; ${i} ${nn_ipbase}
done

# datanode
test -e slaves &amp;&amp; rm slaves
for ((i=1; i&lt;=2; i=i+1 ))
do
    echo datanode${i} &gt;&gt; slaves
done
for ((i=1; i&lt;=3; i=i+1 ))
do
    docker run -itd -h datanode${i} --name=datanode${i} -v /root/cluster-build:/root/cluster-build bigdata:1.0.2
    docker exec datanode${i} cp /root/cluster-build/slaves /opt/hadoop-2.7.3/etc/hadoop/
    cp_config &apos;datanode&apos; ${i} ${dn_ipbase}
done</code></pre></li>
<li><p>编写删除集群脚本</p>
<pre><code>docker stop $(docker ps -q)
docker rm $(docker ps -a -q)</code></pre></li>
</ol>
<h3 id="启动集群"><a href="#启动集群" class="headerlink" title="启动集群"></a>启动集群</h3><p>可以把生产hosts文件中的内容复制到本机的 /etc/hosts 文件中</p>
<pre><code>cat hosts &gt;&gt; /etc/hosts</code></pre><ol>
<li><p>启动zookeeper集群</p>
<pre><code>ssh root@zookeeper1
zkServer.sh start

ssh root@zookeeper2
zkServer.sh start

ssh root@zookeeper3
zkServer.sh start

# 运行 jps 命令 看一下是不是多了一个java线程
jps
# 查看状态
zkServer.sh status</code></pre></li>
<li><p>启动 journalnode 集群，如果失败可以去 /opt/hadoop-2.7.3/logs/ 目录下查看输出</p>
<pre><code>ssh root@zookeeper1
hadoop-daemon.sh start journalnode

ssh root@zookeeper1
hadoop-daemon.sh start journalnode

ssh root@zookeeper1
hadoop-daemon.sh start journalnode</code></pre></li>
<li><p>namenode 格式化</p>
<pre><code>ssh root@namenode1
hdfs namenode -format</code></pre><p> 为了保持一致，直接把 namenode1 的 /root/hadoop/ 目录下的内容拷贝到 namenode2中</p>
<pre><code>scp -r /root/hadoop/ namenode2:/root/</code></pre><p> 在其中一个namenode节点上运行下面的命令，会在 zookeeper 集群中创建一个 /acyouzi 目录</p>
<pre><code>hdfs zkfc -formatZK</code></pre></li>
<li><p>启动datanode</p>
<pre><code>ssh root@datanode1
# 会根据 /etc/hadoop/slaves 文件启动所有的datanode
start-dfs.sh</code></pre></li>
<li><p>启动resourcemanager</p>
<pre><code>ssh root@resourcemanager1
# 会根据 /etc/hadoop/slaves 文件启动所有的启动resourcemanager
start-yarn.sh</code></pre></li>
<li><p>打开浏览器输入 namenode1:50070 namenode2:50070 查看节点状态</p>
</li>
<li><p>往hdfs中放入文件试试</p>
<pre><code>hadoop fs -put ~/test.md /test</code></pre></li>
</ol>
<h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><ol>
<li>在创建 container 的时候务必通过 -h 参数指定主机名，否则启动journalnode节点时会报错，大概是 unknowhost 错误</li>
<li>我shell写的真的很烂</li>
<li>还缺一个启动脚本，在通过docker start $(docker ps -a -q) 启动时给容器分配ip,还没想好怎么写</li>
</ol>

            </div>
          

    
      <footer class="post-footer">
		
		<div class="post-tags">
		  
			<a href="/tags/java/">java</a>
		  
		</div>
		

        
        
  <nav class="post-nav">
    
      <a class="prev" href="/2016/11/04/jvm-Memory/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">java虚拟机的内存布局及对象加载</span>
        <span class="prev-text nav-mobile">Prev</span>
      </a>
    
    
      <a class="next" href="/2016/11/01/hexo-learning/">
        <span class="next-text nav-default">hexo 快速入门</span>
        <span class="prev-text nav-mobile">Next</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>

        
  <div class="comments" id="comments">
    
  </div>


      </footer>
    
  </article>

    </div>

      </div>

      <footer id="colophon"><span class="copyright-year">
    
        &copy;
    
        2016 -
    
    2019
    <span class="footer-author">acyouzi.</span>
</span>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>
    


    




  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  

    <script type="text/javascript" src="/js/src/theme.js?v=1.1"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=1.1"></script>

  </body>
</html>
